### Why Use *Robot Brains*?   Historical Reflections on the *Science* of Artificial Intelligence and Global Commercial Bubbles

*This Note serves as a Preface for the collected* **AI Lab Notes**, *as well as a commentary on the current AI state-of-the-art and NVIDIA Jetsons for practical physical computing and robotics for Edge laboratories.*

#### Backstory

With the greatest of respect: The perspectives presented in this Repository do not represent those of a professional engineer, data sci quant, or physicist. These are the Lab Notes of an emeritus neuroscientist who first trained in digitizing and analyzing EEG, ECG, and other physiological data on the first generation of laboratory instrumentation computers (Digital Equipment Corporation PDP-12) *in the late 1970s.*

Forward-looking at the time, my biomedical research Doctoral program had supported productive computer programming as fulfilling one of its legacy scholarly language degree requirements. We had to develop our own data acquisition and analysis programs for research and scientific journal publications, and FORTH was then the chosen language for directly processing data from from new analog instrumentation and other lab peripherals.

By the 1980s, our behavioral neurophysiology lab had evolved to using 16 bit PDP-11 minicomputers and their first-generation IC-based LSI-11 successors. While doing follow-on research in my NIMH postdoctoral fellowship, I also started studying artificial intelligence and symbolic programming on early personal computers.

Since contemporaneous AI research encompassed modeling cognitive functions and  computation with early primitive model 'neurons', this new study track seemed a valuable scientific asset that could be developmentally enhanced with deep understanding of biological brains and behaviors. So Russell and Norvig's [Artificial Intelligence: A Modern Approach](https://en.m.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach) ultimately became a new foundational textbook for this academic neuroscientist.

Caught up in the *expert system* wave of symbolic AI programming at the outset, the mid-range aim was to become a knowledge engineer, as well as a multi-domain expert.

Nonetheless, for a neuroscientist, it was a tremendous charge to absorb the volumes of [Parallel Distributed Processing](https://direct.mit.edu/books/monograph/4424/Parallel-Distributed-Processing-Volume) when they were first released. Rumelhart, Hinton, Sejnowski, McClelland and the PDP group clearly pointed the connectionist way forward from multi-layered perceptrons toward the current hyperfunctional deep neural networks and machine learning.


After getting a medical school faculty appointment with major teaching responsibilities in functional anatomy and neurosciences, my symbolic programming research progressed into [qualitative process theory](https://archive.org/details/readingsinqualit0000unse) (QPT) and modeling [immune](https://pubmed.ncbi.nlm.nih.gov/8955586/) and [gene regulation](https://pubmed.ncbi.nlm.nih.gov/10564845/) experiments. In the 1990s, the Air Force Office of Scientific Research sponsored some of my projects on multilevel biological processes modeling and wound healing. Working with [ontologies](https://pubmed.ncbi.nlm.nih.gov/16568425/) came later.

I finally started studying artificial neural networks in action after the turn of the new millennium.  First came MatLab experiments with their Neural Networks and Machine Learning Toolboxes and early server-based NVIDIA CUDA GPUs.

![OrinModAI1](https://user-images.githubusercontent.com/71346897/173706883-8b9418da-0ce3-4aed-a1ad-c10251d9fb43.png)

#### On to Robot Brains

Some time before chosing to retire from heavy teaching in favor of doing research, NVIDIA Jetsons appeared on my 'neurosci-hacker radar'.  An early Jetson Nano Developer Kit was bought, then an AGX Xavier and several Xavier NXes.

Almost immediately, I started thinking of the compact Jetsons as ***robot brains*** because they had the integrated GPUs, speed, capacity, and lots of GPIO for realtime handling of multiple sensors, physiological recording, controlling outputs, and modeling cognitive functions.  In specific instances of this, I built JetBot robots and computer vision workstations for outreach donations to a high school robotics teaching lab.

On the research side, computer vision networks were initially the most practically useful AI applications for a neuroscientist, for tasks like auto-segmentation and object identification in biomedical imaging ranging from microscopic histology through magnetic resonance (MR) and computed tomography (CT) of brain and body.

Adding to the robot modality aspects, there was the high performance computing (HPC) capacity for complex behavioral modeling, spatialization of objects, and neuromorphic modeling.  For the neuroscientist, the ability to model a real-time functioning modular volitional and sensorimotor system was particularly attractive, given multi-agent approaches to developing novel silicon nervous systems based on standardized Jetson operating software resources.

So as my emeritus appointment approached, a lot of planning went into setting up an edge AI development laboratory at home.  This turned out to be most timely because the global COVID-19 pandemic started shortly after emeritus conferral, and University research facilities were shut down for nearly three years.

*The collected AI Lab Notes present structured views of the all the development that occurred in my Edge home lab during the years of Pandemic, quarantine, and subsequent University recovery.*

#### Bubble, Bubble, AI Ferment and Trouble?

Over the last several years, the technophilic public's attention and academics have been seized by hyper-competing commercial generative AI applications, based on deep artificial neural networks, exemplified by Open AI's Stable Fusion and Meta's ChatGPT.  

There seems to be a land-rush of corporations to use online Chatbot apps to supplant human employees in public-facing user support positions and others.

Large sums of money and energy are being expended to develop new AI services and infrastructure, with absurd signing bonuses offered to CS, math, and data science grads who can 'code the real deal'.

But beyond the historical decadal waves of interest in symbolic and connectionist artificial intelligence research and development, the current connectionist AI wave seems more like a variation of the 'dotcom bubble' theme.  

**And if you need more concise critical specifics than some pop-tech media pundits are currently shouting, check out what an Open Source GPT model running on my AGX Orin has to say about the situation:**
<img width="1488" height="2266" alt="image" src="https://github.com/user-attachments/assets/5892bf85-f67d-4038-b6b6-aece56fe839a" />

To provide a human perspective on the major facts, AI is starting to work hard for many public and private sector commerical organizations, and it will continue to grow and evolve.  One might expect a down-throttling *correction*, if not a *bursting bubble in AI businesses that continue to *burn* through investment capital without sufficient real product and services earnings *taking off* into growing profits.

***Faites vos jeux:  Rien ne va plus!***

#### *Work in progress...*


**==> Testing AGX Thor JDK 21 performance: ImageJ with head MRI stack, CLIPS IDE with gene regulation model**
<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/0521714f-969a-4520-88a9-be79e940e20f" />


**==> AGX Thor session: JDK 21 running ImageJ with MRI stack, Protege with FMA ontology**
![image](https://github.com/user-attachments/assets/8d9413f0-5fea-402d-be07-ca53b6cd8ef3)

