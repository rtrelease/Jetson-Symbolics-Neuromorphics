### Why Use *Robot Brains*?   Historical Reflections on the Science of Artificial Intelligence within Global Commercial Bubbles

*This Note serves as a preface for the collected* **AI Lab Notes**, *as well as a commentary on the current NVIDIA Jetson state-of-the-art for physical computing, AI, and robotics for Edge laboratories.*

**Backstory**

With the greatest of respect: The perspectives presented in this Repository do not represent those of a professional engineer, data sci quant, or physicist. These are the Lab Notes of an emeritus neuroscientist who first trained on analyzing EEG and other physiological data on the first generation of laboratory instrumentation computers (Digital Equipment Corporation PDP-12) *in the late 1970s.*

Forward-looking at the time, my biomedical research Doctoral program had supported productive computer programming as fulfilling one of its legacy scholarly language requirements. We had to produce our own data acquisition and analysis programs for research and scientific journal publications, and FORTH was then the chosen language for directly processing data from from new analog instrumentation and other lab peripherals.

By the 1980s, our behavioral neurophysiology lab had evolved to using 16 bit PDP-11 minicomputers and their first-generation IC-based LSI-11 successors. While doing follow-on research in an NIMH postdoctoral fellowship, I also started studying artificial intelligence and symbolic programming on early personal computers.

Since contemporaneous AI research encompassed understanding cognitive functions and  computation with early primitive model 'neurons', this newvscientific track seemed a valuable scientific asset that could be enhanced with deep understanding of biological brains and behaviors. Russell and Norvig's [Artificial Intelligence: A Modern Approach](https://en.m.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach) ultimately became a new foundational textbook for this academic neuroscientist.

Caught up in the *expert system* wave of symbolic AI programming at the outset, it was a tremendous charge to absorb the volumes of [Parallel Distributed Processing](https://direct.mit.edu/books/monograph/4424/Parallel-Distributed-Processing-Volume) when they were first released. Rumelhart, Hinton, Sejnowski, McClelland and the PDP group clearly pointed the connectionist way forward from multi-layered perceptrons toward the current hyperfunctional deep neural networks and machine learning we now use.

After getting a medical school faculty appointment with major teaching responsibilities in functional anatomy and neurosciences, my symbolic programming research progressed into [qualitative process theory](https://archive.org/details/readingsinqualit0000unse) (QPT) and modeling immune and gene regulation processes. The Air Force Office of Scientific Research sponsored some of my projects on modeling biological processes and wound healing.

I finally started studying artificial neural networks in action after the turn of the new millennium.  First came MatLab experiments with their Neural Networks and Machine Learning Toolboxes and early server-based NVIDIA GPUs.
![OrinModAI1](https://user-images.githubusercontent.com/71346897/173706883-8b9418da-0ce3-4aed-a1ad-c10251d9fb43.png)

**On to Robot Brains**




<img width="1488" height="2266" alt="image" src="https://github.com/user-attachments/assets/5892bf85-f67d-4038-b6b6-aece56fe839a" />
