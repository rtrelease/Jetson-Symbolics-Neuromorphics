## <u>AI Lab Notes</u>

#### **Gedanken Experiment 1:** Ontologies for semantic linking with deep neural network neuroanatomical structure identifications in brain magnetic resonance images


In a prior [2006 scientific journal article](https://anatomypubs.onlinelibrary.wiley.com/doi/10.1002/ar.b.20095), I reviewed the concepts underlying anatomical reasoning and application of AI research and symbolic programming methods to biostructural inference with large-scale ontologies.

The decade-plus following this work saw the rapid rise of deep neural networks and machine learning methods, presaged by the seminal 1987 PDP Group work on [parallel distributed processing](https://mitpress.mit.edu/9780262680530/parallel-distributed-processing/) and recurrent multilayer networks.  

As an academic neuroscientist and long-time symbolic coder also influenced by PDP (1987) concepts, I had begun studying ANN development with MatLab on NV Kepler-class GPUs.

Across this same post-millennial time frame, enthusiasm for the application of ontologies moderated, while effective anatomical inference in medical imaging has become associated with commercial deep learning systems such as NVIDIA CLARA.  

Major [Open ontologies](https://bioportal.bioontology.org) have largely evolved from 2000s-era frame-based SQL database implementations to flatter descriptive Web Ontology Language (OWL), RDF/XML and other format representations, with archive resources supported by the [National Center for Biomedical Ontology](https://ncbo.bioontology.org/ncbo-summary) and funded by the National Institutes of Health. 

***A focus of this current AI Lab sub-project is to investigate more*** **research-oriented** ***symbolic enhancement of brain imaging network applications.***  The task at hand here is to evaluate which current anatomical ontology might be best used for adding semantic bindings and advanced inference capabilities for structural identification and segmentation nets.

[An informative 2014 paper](https://reader.elsevier.com/reader/sd/pii/S1532046414001555) has studied the integration of several ontologies for a comparable task labeling medical imaging structures for producing anatomy-based model simulations.

Since massive government research funding, academic training programs, corporate teams, publications, and commercial development have already been dedicated to widescale adoption of 'AI' (=$valuable$) for highly regulated clinical radiology systems, *we'll stick here with the deeper basic aspects of neurosymbolic fusion for edge laboratory AI applications and research.*


##### ***FMA and OpenGALEN revisited in 2022***


[The Foundational Model of Anatomy (FMA)](https://reader.elsevier.com/reader/sd/pii/S0169023X03001253) is the premier international professional consensus domain ontology for concepts, structures and relationships in human anatomy, a major base component of the National Library of Medicine's Unified Medical Language System (UMLS). 

To my memory, the original SQL/frames-based knowlege base of FMA presented exactly the same way in Protege, as it does now with the current OWL representation.


 *=--> **Fig. 1:** ImageJ displays a DICOM MRI section with cross-hair pointer placed over the optic nerve, and Protege shows the ontology search and appropriate specific FMA.owl *left optic nerve* entity information*
![image](https://user-images.githubusercontent.com/71346897/190932716-14f41129-bffe-410e-a4ef-d9179c180775.png)


As demonstrated in the Protege entity ontology graph, the left optic nerve is its own entity near the top of the root for the anatomy knowledge mapping...





 *=--> **Fig 2:** ImageJ shows a DICOM MRI section with cross-hair pointer over the left optic nerve, and Protege displays the appropriate OpenGalen.owl general optic nerve entity information*
![image](https://user-images.githubusercontent.com/71346897/189554214-dd2d7983-48fc-4f83-97c8-c6b2ae4dc975.png)



To be continued...
